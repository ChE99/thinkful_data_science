{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open file and inspect first five rows.\n",
    "df_A = pd.read_csv('creditcard.csv')\n",
    "df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape.\n",
    "df_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls.\n",
    "df_A.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64 \n",
      "\n",
      "0.00172748563062\n"
     ]
    }
   ],
   "source": [
    "# Show class distribution.\n",
    "print(df_A['Class'].value_counts(),'\\n')\n",
    "\n",
    "# Show proportion of fraudulent transactions.\n",
    "print((df_A['Class'] == 1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a highly imbalanced dataset, and if the model were to predict nothing but 0, it would still be almost 99.83% accurate. Two methods that are best suited for imbalanced datasets will be compared - logistic regression and random forest classification. Furthermore, up and down samplng, which are effective techniques for imbalanced datasets, will be conducted within each method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.999157332959\n"
     ]
    }
   ],
   "source": [
    "# Set the variables.\n",
    "X_B1 = df_A.iloc[:,1:30]\n",
    "Y_B1 = df_A['Class']\n",
    "\n",
    "# Split into train and test data.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train_B1, X_test_B1, y_train_B1, y_test_B1 = train_test_split(X_B1, Y_B1, test_size = .3, random_state=25)\n",
    "\n",
    "# Standardize training features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_B1 = StandardScaler().fit(X_train_B1)\n",
    "X_train_B1_trans = scaler_B1.transform(X_train_B1)\n",
    "\n",
    "# Fit the model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X_train_B1_trans, y_train_B1)\n",
    "\n",
    "# Standardize test features based on training set.\n",
    "X_test_B1_trans = scaler_B1.transform(X_test_B1)\n",
    "\n",
    "# Make predictions.\n",
    "logr_pred_B1 = logr.predict(X_test_B1_trans)\n",
    "\n",
    "# Accuracy score.\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Score:', accuracy_score(y_test_B1, logr_pred_B1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85275    10]\n",
      " [   62    96]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_B1 = confusion_matrix(y_test_B1, logr_pred_B1)\n",
    "print(confusion_matrix_B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85285\n",
      "          1       0.91      0.61      0.73       158\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification matrix.\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_B1, logr_pred_B1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's sensitivity is relatively low at 0.61, which means it performs rather poorly in identifying fraudulent transactions, i.e., true positives; hence, the need for up or down sampling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Up-Sample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    284315\n",
       "0    284315\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes.\n",
    "df_B2_maj = df_A[df_A['Class']==0]\n",
    "df_B2_min = df_A[df_A['Class']==1]\n",
    "\n",
    "# Upsample minority class.\n",
    "from sklearn.utils import resample\n",
    "df_B2_min_up = resample(df_B2_min, replace=True, n_samples=284315, random_state=123)\n",
    "\n",
    "# Combine majority class with upsampled minority class.\n",
    "df_B2_up = pd.concat([df_B2_maj, df_B2_min_up])\n",
    "\n",
    "# Display new class counts.\n",
    "df_B2_up['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.948349541881\n"
     ]
    }
   ],
   "source": [
    "# Set the variables.\n",
    "X_B2 = df_B2_up.iloc[:,1:30]\n",
    "Y_B2 = df_B2_up['Class']\n",
    "\n",
    "# Split into train and test data.\n",
    "X_train_B2, X_test_B2, y_train_B2, y_test_B2 = train_test_split(X_B2, Y_B2, test_size = .3, random_state=25)\n",
    "\n",
    "# Standardize training features.\n",
    "scaler_B2 = StandardScaler().fit(X_train_B2)\n",
    "X_train_B2_trans = scaler_B2.transform(X_train_B2)\n",
    "\n",
    "# Fit the model.\n",
    "logr.fit(X_train_B2_trans, y_train_B2)\n",
    "\n",
    "# Standardize test features based on training set.\n",
    "X_test_B2_trans = scaler_B2.transform(X_test_B2)\n",
    "\n",
    "# Make predictions.\n",
    "logr_pred_B2 = logr.predict(X_test_B2_trans)\n",
    "\n",
    "# Accuracy score.\n",
    "print('Score:', accuracy_score(y_test_B2, logr_pred_B2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83707  1934]\n",
      " [ 6877 78071]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix.\n",
    "confusion_matrix_B2 = confusion_matrix(y_test_B2, logr_pred_B2)\n",
    "print(confusion_matrix_B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95     85641\n",
      "          1       0.98      0.92      0.95     84948\n",
      "\n",
      "avg / total       0.95      0.95      0.95    170589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification matrix.\n",
    "print(classification_report(y_test_B2, logr_pred_B2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Down-Sample Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class.\n",
    "df_B3_maj_down = resample(df_B2_maj, replace=False, n_samples=492, random_state=123)\n",
    "\n",
    "# Combine minority class with downsampled majority class.\n",
    "df_B3_down = pd.concat([df_B2_min, df_B3_maj_down])\n",
    "\n",
    "# Display new class counts.\n",
    "df_B3_down['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.942567567568\n"
     ]
    }
   ],
   "source": [
    "# Set the variables.\n",
    "X_B3 = df_B3_down.iloc[:,1:30]\n",
    "Y_B3 = df_B3_down['Class']\n",
    "\n",
    "# Split into train and test data.\n",
    "X_train_B3, X_test_B3, y_train_B3, y_test_B3 = train_test_split(X_B3, Y_B3, test_size = .3, random_state=25)\n",
    "\n",
    "# Standardize training features.\n",
    "scaler_B3 = StandardScaler().fit(X_train_B3)\n",
    "X_train_B3_trans = scaler_B3.transform(X_train_B3)\n",
    "\n",
    "# Fit the model.\n",
    "logr.fit(X_train_B3_trans, y_train_B3)\n",
    "\n",
    "# Standardize test features based on training set.\n",
    "X_test_B3_trans = scaler_B3.transform(X_test_B3)\n",
    "\n",
    "# Make predictions.\n",
    "logr_pred_B3 = logr.predict(X_test_B3_trans)\n",
    "\n",
    "# Accuracy score.\n",
    "print('Score:', accuracy_score(y_test_B3, logr_pred_B3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147   1]\n",
      " [ 16 132]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix.\n",
    "confusion_matrix_B3 = confusion_matrix(y_test_B3, logr_pred_B3)\n",
    "print(confusion_matrix_B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.95       148\n",
      "          1       0.99      0.89      0.94       148\n",
      "\n",
      "avg / total       0.95      0.94      0.94       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification matrix.\n",
    "print(classification_report(y_test_B3, logr_pred_B3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.999543555353\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the original training set. \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_B1_trans, y_train_B1)\n",
    "\n",
    "# Predict on the original test set.\n",
    "pred_rfc_C1 = rfc.predict(X_test_B1_trans)\n",
    "\n",
    "# Accuracy score.\n",
    "print('Score:', accuracy_score(y_test_B1, pred_rfc_C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85273    12]\n",
      " [   27   131]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix.\n",
    "confusion_matrix_C1 = confusion_matrix(y_test_B1, pred_rfc_C1)\n",
    "print(confusion_matrix_C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85285\n",
      "          1       0.92      0.83      0.87       158\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification matrix.\n",
    "print(classification_report(y_test_B1, pred_rfc_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Up-Sample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.999970689787\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the up-sample training set.\n",
    "rfc.fit(X_train_B2_trans, y_train_B2)\n",
    "\n",
    "# Predict on the up-sample test set.\n",
    "pred_rfc_C2 = rfc.predict(X_test_B2_trans)\n",
    "\n",
    "# Accuracy score.\n",
    "print('Score:', accuracy_score(y_test_B2, pred_rfc_C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85636     5]\n",
      " [    0 84948]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix.\n",
    "confusion_matrix_C2 = confusion_matrix(y_test_B2, pred_rfc_C2)\n",
    "print(confusion_matrix_C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85641\n",
      "          1       1.00      1.00      1.00     84948\n",
      "\n",
      "avg / total       1.00      1.00      1.00    170589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification matrix.\n",
    "print(classification_report(y_test_B2, pred_rfc_C2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Down-Sample Majority Class¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.935810810811\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the down-sample training set.\n",
    "rfc.fit(X_train_B3_trans, y_train_B3)\n",
    "\n",
    "# Predict on the down-sample test set.\n",
    "pred_rfc_C3 = rfc.predict(X_test_B3_trans)\n",
    "\n",
    "# Accuracy score.\n",
    "print('Score:', accuracy_score(y_test_B3, pred_rfc_C3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147   1]\n",
      " [ 18 130]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix.\n",
    "confusion_matrix_C3 = confusion_matrix(y_test_B3, pred_rfc_C3)\n",
    "print(confusion_matrix_C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       148\n",
      "          1       0.99      0.88      0.93       148\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification matrix.\n",
    "print(classification_report(y_test_B3, pred_rfc_C3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Up-sampling the dataset prior to random forest classification appears to provide the best results. However, the model could potentially be overfit, therefore, it should be evaluated on an unseen test set prior to making a final conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
