{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(THE, ORPHANS, .)</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Near, the, ruins, of, the, castle, of, Rossmo...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(As, long, as, she, was, able, to, work, ,, sh...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Mary, was, at, this, time, about, twelve, yea...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(One, evening, she, was, sitting, at, the, foo...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1\n",
       "0                                  (THE, ORPHANS, .)  Edgeworth\n",
       "1  (Near, the, ruins, of, the, castle, of, Rossmo...  Edgeworth\n",
       "2  (As, long, as, she, was, able, to, work, ,, sh...  Edgeworth\n",
       "3  (Mary, was, at, this, time, about, twelve, yea...  Edgeworth\n",
       "4  (One, evening, she, was, sitting, at, the, foo...  Edgeworth"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "parents = gutenberg.raw('edgeworth-parents.txt')\n",
    "ball = gutenberg.raw('chesterton-ball.txt')\n",
    "\n",
    "# Remove chapter indicator.\n",
    "parents = re.sub(r'CHAPTER .*', '', parents)\n",
    "ball = re.sub(r'CHAPTER .*', '', ball)\n",
    "\n",
    "# Apply text cleaner function.\n",
    "parents = text_cleaner(parents)\n",
    "ball = text_cleaner(ball)\n",
    "\n",
    "# Parse the cleaned novels.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "parents_doc = nlp(parents)\n",
    "ball_doc = nlp(ball)\n",
    "\n",
    "# Group into sentences.\n",
    "parents_sents_bow = [[sent, \"Edgeworth\"] for sent in parents_doc.sents]\n",
    "ball_sents_bow = [[sent, \"Chesterton\"] for sent in ball_doc.sents]\n",
    "sentences_bow = pd.DataFrame(parents_sents_bow + ball_sents_bow)\n",
    "sentences_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "parentswords = bag_of_words(parents_doc)\n",
    "ballwords = bag_of_words(ball_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(parentswords + ballwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n",
      "Processing row 7500\n",
      "Processing row 8000\n",
      "Processing row 8500\n",
      "Processing row 9000\n",
      "Processing row 9500\n",
      "Processing row 10000\n",
      "Processing row 10500\n",
      "Processing row 11000\n",
      "Processing row 11500\n",
      "Processing row 12000\n",
      "Processing row 12500\n",
      "Processing row 13000\n",
      "Processing row 13500\n",
      "Processing row 14000\n",
      "Processing row 14500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authority</th>\n",
       "      <th>shout</th>\n",
       "      <th>and</th>\n",
       "      <th>heath</th>\n",
       "      <th>seize</th>\n",
       "      <th>lustrous</th>\n",
       "      <th>imagination</th>\n",
       "      <th>inclined</th>\n",
       "      <th>candlestick</th>\n",
       "      <th>physical</th>\n",
       "      <th>...</th>\n",
       "      <th>family</th>\n",
       "      <th>miracle</th>\n",
       "      <th>coast</th>\n",
       "      <th>dunstable</th>\n",
       "      <th>utterly</th>\n",
       "      <th>quietly</th>\n",
       "      <th>leg</th>\n",
       "      <th>satisfied</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(THE, ORPHANS, .)</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Near, the, ruins, of, the, castle, of, Rossmo...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(As, long, as, she, was, able, to, work, ,, sh...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mary, was, at, this, time, about, twelve, yea...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(One, evening, she, was, sitting, at, the, foo...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  authority shout and heath seize lustrous imagination inclined candlestick  \\\n",
       "0         0     0   0     0     0        0           0        0           0   \n",
       "1         0     0   0     0     0        0           0        0           0   \n",
       "2         0     0   0     0     0        0           0        0           0   \n",
       "3         0     0   0     0     0        0           0        0           0   \n",
       "4         0     0   0     0     0        0           0        0           0   \n",
       "\n",
       "  physical     ...     family miracle coast dunstable utterly quietly leg  \\\n",
       "0        0     ...          0       0     0         0       0       0   0   \n",
       "1        0     ...          0       0     0         0       0       0   0   \n",
       "2        0     ...          0       0     0         0       0       0   0   \n",
       "3        0     ...          0       0     0         0       0       0   0   \n",
       "4        0     ...          0       0     0         0       0       0   0   \n",
       "\n",
       "  satisfied                                      text_sentence text_source  \n",
       "0         0                                  (THE, ORPHANS, .)   Edgeworth  \n",
       "1         0  (Near, the, ruins, of, the, castle, of, Rossmo...   Edgeworth  \n",
       "2         0  (As, long, as, she, was, able, to, work, ,, sh...   Edgeworth  \n",
       "3         0  (Mary, was, at, this, time, about, twelve, yea...   Edgeworth  \n",
       "4         0  (One, evening, she, was, sitting, at, the, foo...   Edgeworth  \n",
       "\n",
       "[5 rows x 3022 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe with features. \n",
    "word_counts = bow_features(sentences_bow, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Set variables.\n",
    "Y_bow = word_counts['text_source']\n",
    "X_bow = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "# Train, test split.\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, Y_bow, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb train score: 0.915985773335\n",
      "mnb test score: 0.906481273828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_bow, y_train_bow)\n",
    "print('mnb train score:', mnb.score(X_train_bow, y_train_bow))\n",
    "print('mnb test score:', mnb.score(X_test_bow, y_test_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr train score: 0.934922618475\n",
      "lr test score: 0.891455483292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_bow, y_train_bow)\n",
    "print('lr train score:', lr.score(X_train_bow, y_train_bow))\n",
    "print('lr test score:', lr.score(X_test_bow, y_test_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Test on a different corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the Brown data.\n",
    "brown = gutenberg.raw('chesterton-brown.txt')\n",
    "brown = re.sub(r'VOLUME \\w+', '', brown)\n",
    "brown = re.sub(r'CHAPTER \\w+', '', brown)\n",
    "brown = text_cleaner(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n"
     ]
    }
   ],
   "source": [
    "# Parse the cleaned data.\n",
    "brown_doc = nlp(brown)\n",
    "brown_sents = [[sent, \"Chesterton\"] for sent in brown_doc.sents]\n",
    "brown_sents = brown_sents[0:len(parents_sents_bow)]\n",
    "brown_sentences = pd.DataFrame(brown_sents)\n",
    "brown_bow = bow_features(brown_sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr score:  0.456404736276\n",
      "mnb score:  0.567814854682\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X_brown_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Edgeworth'].index],\n",
    "    brown_bow.drop(['text_sentence','text_source'], 1)\n",
    "), axis=0)\n",
    "y_brown_test = pd.concat([y_train[y_train=='Edgeworth'],\n",
    "                         pd.Series(['Chesterton'] * brown_bow.shape[0])])\n",
    "'''\n",
    "# Set variables.\n",
    "Y_brown = brown_bow['text_source']\n",
    "X_brown = np.array(brown_bow.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "# RUn the models and return scores.\n",
    "print('lr score: ', lr.score(X_brown, Y_brown))\n",
    "print('mnb score: ', mnb.score(X_brown, Y_brown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ The Parent ' s Assistant , by Maria Edgeworth ]</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE ORPHANS .</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Near the ruins of the castle of Rossmore , in ...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mary was at this time about twelve years old .</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" No need to stop the wheel , Mary , dear , fo...</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1\n",
       "0  [ The Parent ' s Assistant , by Maria Edgeworth ]  Edgeworth\n",
       "1                                      THE ORPHANS .  Edgeworth\n",
       "2  Near the ruins of the castle of Rossmore , in ...  Edgeworth\n",
       "3     Mary was at this time about twelve years old .  Edgeworth\n",
       "4  \" No need to stop the wheel , Mary , dear , fo...  Edgeworth"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process paragraphs.\n",
    "parents_p = gutenberg.paras('edgeworth-parents.txt')\n",
    "parents_paras=[]\n",
    "for paragraph in parents_p:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    parents_paras.append(' '.join(para))\n",
    "\n",
    "ball_p = gutenberg.paras('chesterton-ball.txt')\n",
    "ball_paras=[]\n",
    "for paragraph in ball_p:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    ball_paras.append(' '.join(para))\n",
    "\n",
    "parents_sents_tfidf = [[sent, \"Edgeworth\"] for sent in parents_paras]\n",
    "ball_sents_tfidf = [[sent, \"Chesterton\"] for sent in ball_paras]\n",
    "sentences_tfidf = pd.DataFrame(parents_sents_tfidf + ball_sents_tfidf)\n",
    "sentences_tfidf.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, test split.\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(sentences_tfidf[0], sentences_tfidf[1], test_size=0.3, random_state=123)\n",
    "\n",
    "# Set the tfidf vectorizer.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb train score: 0.938638799571\n",
      "mnb test score: 0.891875\n"
     ]
    }
   ],
   "source": [
    "# Set the Naive Bayes pipeline to run on the train set and apply on the test set.\n",
    "from sklearn.pipeline import Pipeline\n",
    "mnb_pipe = Pipeline([('tfidf', vectorizer), ('clf', mnb)])\n",
    "\n",
    "# Run train and test scores.\n",
    "mnb_pipe.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('mnb train score:', mnb_pipe.score(X_train_tfidf, y_train_tfidf))\n",
    "print('mnb test score:', mnb_pipe.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb train score: 0.913183279743\n",
      "mnb test score: 0.86375\n"
     ]
    }
   ],
   "source": [
    "# Set the Logistic Regression pipeline to run on the train set and apply on the test set.\n",
    "lr_pipe = Pipeline([('tfidf', vectorizer), ('clf', lr)])\n",
    "\n",
    "# Run train and test scores.\n",
    "lr_pipe.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('mnb train score:', lr_pipe.score(X_train_tfidf, y_train_tfidf))\n",
    "print('mnb test score:', lr_pipe.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Test on a different corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ The Wisdom of Father Brown by G . K . Cheste...</td>\n",
       "      <td>Chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I .</td>\n",
       "      <td>Chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE consulting - rooms of Dr Orion Hood , the ...</td>\n",
       "      <td>Chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr Hood paced the length of his string of apar...</td>\n",
       "      <td>Chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fate , being in a funny mood , pushed the door...</td>\n",
       "      <td>Chesterton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0           1\n",
       "0  [ The Wisdom of Father Brown by G . K . Cheste...  Chesterton\n",
       "1                                                I .  Chesterton\n",
       "2  THE consulting - rooms of Dr Orion Hood , the ...  Chesterton\n",
       "3  Dr Hood paced the length of his string of apar...  Chesterton\n",
       "4  Fate , being in a funny mood , pushed the door...  Chesterton"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_p = gutenberg.paras('chesterton-brown.txt')\n",
    "brown_paras=[]\n",
    "for paragraph in brown_p:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    brown_paras.append(' '.join(para))\n",
    "    \n",
    "brown_sents_tfidf = [[sent, \"Chesterton\"] for sent in brown_paras]\n",
    "brown_tfidf = pd.DataFrame(brown_sents_tfidf)\n",
    "brown_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb score: 0.310938845823\n",
      "lr test score: 0.161068044789\n"
     ]
    }
   ],
   "source": [
    "print('mnb score:', mnb_pipe.score(brown_tfidf[0], brown_tfidf[1]))\n",
    "print('lr test score:', lr_pipe.score(brown_tfidf[0], brown_tfidf[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb train score: 0.924973204716\n",
      "mnb test score: 0.9025\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = TfidfVectorizer(max_df=0.25,\n",
    "                             min_df=4,\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True\n",
    "                            )\n",
    "mnb_pipe2 = Pipeline([('tfidf', vectorizer2), ('clf', mnb)])\n",
    "mnb_pipe2.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('mnb train score:', mnb_pipe2.score(X_train_tfidf, y_train_tfidf))\n",
    "print('mnb test score:', mnb_pipe2.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words Naive Bayes model achieved the highest score on the test set at 90%. Modifying the tfidf Naive Bayes model, on the other hand, marginally improved the score from 89% to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
